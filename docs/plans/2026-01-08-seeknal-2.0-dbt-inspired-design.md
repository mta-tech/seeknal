# Seeknal 2.0: dbt-Inspired Unified Data + MLOps Platform

**Date:** 2026-01-08
**Status:** Design Complete
**Author:** Brainstorming Session

---

## Executive Summary

Transform Seeknal from a feature store into a **unified data + MLOps platform** where data engineers and ML engineers share the same abstractions, inspired by dbt's successful patterns.

### Vision

```
Traditional (Fragmented):
  Data Pipeline → Features → [GAP] → Model Training → [GAP] → Model Serving
                              ↑                         ↑
                         Train-test skew          Different infra

Seeknal 2.0 (Unified):
  Sources → Transforms → Features → Model (as transform) → Enriched Data
                            ↓                ↓
                     Offline Store      Online Store
                     (training)         (real-time prediction)
                            ↓                ↓
                     Same feature definitions = No skew
```

### Key Problems Solved

1. **Different tools** - Data engineers use Spark/SQL, ML engineers use notebooks → Unified abstractions
2. **Handoff friction** - Analytics-ready to ML-ready requires rework → Seamless flow
3. **Visibility gap** - Can't trace data lineage end-to-end → Full DAG visualization

---

## 1. Core Concepts & Mental Model

### Node-Based Architecture

Everything in Seeknal 2.0 is a **Node** in a DAG:

```
Node Types:
├── Source          → External data (Hive, Parquet, API, database)
├── Transform       → Data transformation (SQL, Python, Spark, DuckDB)
├── FeatureGroup    → Feature engineering (existing, enhanced)
├── Model           → ML model as transformation (NEW)
├── Rule            → Business logic snippet (from common config)
├── Aggregation     → Reusable aggregation pattern (NEW)
└── Exposure        → Downstream consumer (dashboard, API, report)
```

### Ownership Boundaries

| Layer | Owner | Nodes |
|-------|-------|-------|
| Foundation | Data Engineers | Sources, Transforms |
| Features | Both | FeatureGroups, Aggregations |
| Application | ML Engineers | Models, Exposures |

---

## 2. Dependency Declaration System

### Core Functions

```python
from seeknal import source, ref, use_transform, use_rule

# Reference external data sources
df = source("traffic_day")  # From common config
df = source("hive", "eureka_feateng.user_events")  # Inline

# Reference upstream nodes
user_features = ref("user_demographics")  # Creates DAG edge

# Use reusable transformations
df = use_transform("rename_subscriber_type", df)

# Use reusable rules/expressions
df = df.filter(use_rule("callExpression"))
```

### DAG Building

Every call automatically:
1. **Registers the dependency** in the manifest
2. **Validates existence** at parse time
3. **Creates a DAG edge**
4. **Tracks lineage** for documentation

### Example Feature Group

```python
@feature_group(
    name="user_call_features",
    entity=Entity("user", join_keys=["msisdn"]),
)
def user_call_features():
    calls = source("traffic_day")
    user_info = ref("user_demographics")

    calls = use_transform("rename_subscriber_type", calls)
    voice_calls = calls.filter(use_rule("callExpression"))

    return voice_calls.join(user_info, on="msisdn")
```

---

## 3. Enhanced Common Config (Macro System)

### Parameterized Components

```yaml
# common.yml
transformations:
  - id: rename_column_values
    className: ai.eureka.featureengine.transformers.ColumnValueRenamed
    params:
      inputCol: "{{ input_col }}"
      outputCol: "{{ output_col }}"
      valueMappings: "{{ mappings }}"

  - id: aggregate_by_window
    className: ai.eureka.featureengine.aggregators.WindowAggregator
    params:
      groupBy: "{{ group_cols }}"
      windowDays: "{{ window_days | default(7) }}"
      aggregations: "{{ agg_expressions }}"

rules:
  - id: filter_by_service
    rule:
      value: "service_type = '{{ service_type }}'"
```

### Usage with Parameters

```python
# Reusable with different parameters
df = use_transform("rename_column_values", df,
    input_col="payment_category",
    output_col="sub_type",
    mappings=[
        {"fromValue": "Prepaid", "toValue": "prepaid"},
        {"fromValue": "Postpaid", "toValue": "postpaid"},
    ]
)

# Parameterized rules
voice_df = df.filter(use_rule("filter_by_service", service_type="Voice"))
sms_df = df.filter(use_rule("filter_by_service", service_type="Sms"))
```

### Macro Composition

```yaml
transformations:
  - id: standard_user_cleanup
    steps:
      - use_transform: rename_column_values
        params:
          input_col: payment_category
          output_col: sub_type
      - use_transform: filter_nulls
        params:
          columns: ["msisdn", "date_id"]
      - use_rule: callExpression
```

---

## 4. DAG & Lineage System

### Manifest Structure

```json
{
  "metadata": {
    "project": "eureka_feateng",
    "generated_at": "2026-01-08T10:30:00Z",
    "seeknal_version": "2.0.0"
  },
  "nodes": {
    "source.traffic_day": {
      "type": "source",
      "config": {"table": "feateng_integtest.db_traffic_hourly"},
      "columns": ["msisdn", "date_id", "site_id", "hit", "duration"]
    },
    "feature_group.user_call_features": {
      "type": "feature_group",
      "depends_on": ["source.traffic_day", "feature_group.user_demographics"],
      "columns": ["msisdn", "total_calls", "avg_duration", "sub_type"]
    }
  },
  "edges": [
    {"from": "source.traffic_day", "to": "feature_group.user_call_features"}
  ]
}
```

### Selection Syntax (dbt-inspired)

```bash
seeknal run --select user_call_features      # Specific node
seeknal run --select +user_call_features     # With upstream
seeknal run --select user_call_features+     # With downstream
seeknal run --select +user_call_features+    # Full lineage
seeknal run --select tag:daily               # By tag
seeknal run --select type:model              # By type
seeknal run --select state:modified          # Changed only
```

---

## 5. Model as Transformation

### Core Concept

A Model is a transformation that:
- Takes features as input
- Produces prediction columns as output
- Has train and transform modes
- Tracks lineage to training data

### With Fluent Builder Aggregation

```python
from seeknal import model, ref
from seeknal.aggregation import AggregationBuilder

@model(
    name="churn_predictor",
    output_columns=["churn_probability", "churn_risk_tier"],

    aggregation=lambda: (
        AggregationBuilder(
            id_col="msisdn",
            feature_date_col="event_date",
            application_date_col="prediction_date"
        )
        .feature("call_count")
            .basic(["sum", "mean", "max", "count"])
            .rolling([(1, 7), (8, 30), (31, 90)], ["sum", "count"])
            .ratio((1, 30), (31, 90), ["sum"])
        .feature("duration")
            .basic(["sum", "mean"])
            .rolling([(1, 30)], ["sum", "mean"])
        .feature("is_international")
            .since("is_international == 1", ["count", "sum"])
        .build()
    )
)
class ChurnPredictor:

    def train(self, context):
        events = ref("user_call_events").offline(
            start_date="2025-01-01",
            end_date="2025-12-31"
        )

        # Fluent API aggregation applied
        user_features = context.aggregate(events)

        labels = source("churn_labels")
        training_data = user_features.join(labels, on="msisdn")

        self.model = XGBClassifier()
        self.model.fit(training_data[self.feature_cols], training_data["churned"])
        return self.model

    def transform(self, events_df, context):
        user_features = context.aggregate(events_df)
        user_features["churn_probability"] = self.model.predict_proba(...)[:, 1]
        return user_features
```

### Reusable Aggregation in Common Config

```yaml
# common.yml
aggregations:
  - id: user_behavioral_features
    id_col: msisdn
    feature_date_col: event_date
    application_date_col: prediction_date
    features:
      - name: call_count
        basic: [sum, mean, max, count]
        rolling:
          - window: [1, 7]
            aggs: [sum, count]
          - window: [8, 30]
            aggs: [sum, count]
        ratio:
          - numerator: [1, 30]
            denominator: [31, 90]
            aggs: [sum]
```

```python
@model(
    name="churn_predictor",
    aggregation=use_aggregation("user_behavioral_features")
)
class ChurnPredictor:
    # ...
```

### No Train-Serve Skew

```
Training:  events → SecondOrderAggregator(rules) → features → model.fit()
                            ↑
                    Same rules definition
                            ↓
Inference: events → SecondOrderAggregator(rules) → features → model.predict()
```

---

## 6. Discovery & Documentation

### Auto-Generated Catalog

```bash
$ seeknal docs generate
$ seeknal docs serve

# Opens http://localhost:8080 with:
# - Full node catalog
# - Interactive lineage viewer
# - Search functionality
# - Column-level documentation
```

### Search Within Project

```bash
$ seeknal search "call duration"

Found 5 nodes matching "call duration":
  feature_group.user_call_features
  aggregation.user_behavioral_features
  source.traffic_day
  transform.duration_bucketer
```

### Inline Documentation

```python
@feature_group(
    name="user_call_features",
    description="User-level aggregated call behavior features",
    owner="data-engineering@company.com",
    tags=["calls", "user", "daily"],
    columns={
        "msisdn": "Unique user identifier",
        "total_calls": "Total number of calls",
    }
)
def user_call_features():
    # ...
```

---

## 7. CLI & Developer Experience

### Parse with Diff

```bash
$ seeknal parse

✓ Parsed 54 nodes (was 53)

═══════════════════════════════════════════════════════════════
                         CHANGES DETECTED
═══════════════════════════════════════════════════════════════

+ ADDED (1 node)
  + feature_group.user_sms_features

~ MODIFIED (2 nodes)
  ~ feature_group.user_call_features
    - columns: [msisdn, total_calls, avg_duration]
    + columns: [msisdn, total_calls, avg_duration, call_days]
```

### YAML Development Workflow

#### Step 1: Scaffold

```bash
$ seeknal draft feature-group user_engagement

✓ Created: draft_feature_group_user_engagement.yml
```

#### Step 2: Edit & Dry Run

```bash
$ vim draft_feature_group_user_engagement.yml
$ seeknal dry-run draft_feature_group_user_engagement.yml

Executing preview (limit 10 rows)...
┌──────────────┬────────────────┬───────────────┐
│ msisdn       │ activity_score │ activity_tier │
├──────────────┼────────────────┼───────────────┤
│ 628123456789 │ 87.5           │ medium        │
└──────────────┴────────────────┴───────────────┘

Ready to apply? Run: seeknal apply draft_feature_group_user_engagement.yml
```

#### Step 3: Apply

```bash
$ seeknal apply draft_feature_group_user_engagement.yml

Moving file...
  FROM: ./draft_feature_group_user_engagement.yml
  TO:   ./seeknal/features/user_engagement.yml

✓ Added to DAG
✓ Manifest updated
```

### Scaffold Templates

```bash
seeknal draft source <name>
seeknal draft transform <name>
seeknal draft feature-group <name>
seeknal draft model <name>
seeknal draft aggregation <name>
seeknal draft rule <name>

# Interactive mode
seeknal draft --interactive

# From existing
seeknal draft --from feature_group.user_call_features new_features
```

### Full Command Reference

```bash
# Core workflow
seeknal parse              # Build DAG, show diff
seeknal run                # Execute nodes
seeknal test               # Data quality tests
seeknal docs               # Generate & serve docs

# Discovery
seeknal list               # List nodes by type
seeknal search             # Search within project
seeknal lineage            # Show dependencies
seeknal impact             # Show downstream impact

# Development
seeknal draft              # Scaffold new YAML
seeknal dry-run            # Preview transformation
seeknal apply              # Add to DAG
seeknal validate           # Validate configs
seeknal diff               # Compare versions

# Migration
seeknal migrate analyze    # Analyze project
seeknal migrate plan       # Generate migration plan
seeknal migrate apply      # Execute migration
```

---

## 8. Migration Path

### Incremental Adoption

```
┌─────────────────────────────────────────────────────────────┐
│                    SEEKNAL 2.0                              │
├─────────────────────────────────────────────────────────────┤
│  NEW: ref(), source(), DAG, Lineage, Docs                   │
│  NEW: YAML workflow (draft → dry-run → apply)               │
│  NEW: Model as Transformation                               │
├─────────────────────────────────────────────────────────────┤
│  ENHANCED: Common config with parameters                    │
│  ENHANCED: Aggregations with fluent builder                 │
├─────────────────────────────────────────────────────────────┤
│  UNCHANGED: Existing FeatureGroup, Flow, Entity APIs        │
│  UNCHANGED: DuckDB & Spark engines                          │
│  UNCHANGED: Offline/Online stores                           │
└─────────────────────────────────────────────────────────────┘
```

### Phase 1: Existing Code Works As-Is

```python
# OLD CODE - Still works
fg = FeatureGroup(
    name="user_call_features",
    entity=Entity(name="user", join_keys=["msisdn"]),
)
fg.set_dataframe(df).set_features()
fg.write()
```

### Phase 2: Opt-In to DAG Features

```python
# Add ref()/source() for lineage
df = source("traffic_day")
df = df.join(ref("user_demographics"), on="msisdn")
```

### Compatibility Matrix

| Feature | Seeknal 1.x | Seeknal 2.0 |
|---------|-------------|-------------|
| FeatureGroup API | ✓ | ✓ |
| Flow API | ✓ | ✓ |
| DuckDB/Spark Engines | ✓ | ✓ |
| common.yml | ✓ | ✓ (enhanced) |
| ref()/source() | ✗ | ✓ (new) |
| DAG/Lineage | ✗ | ✓ (new) |
| Model nodes | ✗ | ✓ (new) |
| YAML workflow | ✗ | ✓ (new) |

---

## 9. Implementation Roadmap

### Phase 1: Foundation (Weeks 1-4)
- [ ] Implement `ref()`, `source()`, `use_transform()`, `use_rule()`
- [ ] Build manifest generation (`seeknal parse`)
- [ ] Add diff detection and display
- [ ] Create DAG data structure

### Phase 2: Common Config Enhancement (Weeks 5-6)
- [ ] Add `{{ }}` templating to common.yml
- [ ] Implement parameterized transforms and rules
- [ ] Add macro composition support

### Phase 3: CLI & Workflow (Weeks 7-10)
- [ ] Implement `seeknal run` with selection syntax
- [ ] Build `seeknal draft` scaffolding
- [ ] Create `seeknal dry-run` preview
- [ ] Implement `seeknal apply` workflow

### Phase 4: Documentation (Weeks 11-12)
- [ ] Build catalog generation
- [ ] Create lineage visualization
- [ ] Implement search functionality
- [ ] Add `seeknal docs serve`

### Phase 5: Model Integration (Weeks 13-16)
- [ ] Implement Model node type
- [ ] Integrate SecondOrderAggregator fluent builder
- [ ] Add `use_aggregation()` for common config
- [ ] Build train/transform pipeline

### Phase 6: Migration & Polish (Weeks 17-18)
- [ ] Create `seeknal migrate` tooling
- [ ] Write migration documentation
- [ ] Performance optimization
- [ ] Beta testing with real projects

---

## 10. Success Metrics

| Metric | Current | Target |
|--------|---------|--------|
| Time to understand data lineage | Hours | Minutes |
| Code duplication in transforms | High | Low (via macros) |
| Train-serve skew incidents | Occasional | Zero |
| Onboarding time for new engineers | Weeks | Days |
| Documentation coverage | Manual | 100% auto-generated |

---

## Appendix A: Full YAML Schema Examples

### Source

```yaml
kind: source
name: traffic_day
description: "Hourly traffic data from network"
owner: platform-team@company.com
tags: [traffic, network]
source: hive
table: feateng_integtest.db_traffic_hourly
params:
  dateCol: date_id
  idCol: msisdn
columns:
  msisdn: "User phone number"
  date_id: "Event date"
  hit: "Number of network hits"
  duration: "Session duration in seconds"
freshness:
  warn_after: 24h
  error_after: 48h
```

### Transform

```yaml
kind: transform
name: activity_score
description: "Calculate user activity score"
owner: data-team@company.com
tags: [scoring]
inputs:
  - ref: user_call_features
  - ref: user_sms_features
params:
  weights:
    calls: 0.4
    sms: 0.3
    data: 0.3
transform: |
  SELECT
    msisdn,
    (total_calls * {{ weights.calls }} +
     total_sms * {{ weights.sms }}) AS activity_score
  FROM {{ ref('user_call_features') }} c
  JOIN {{ ref('user_sms_features') }} s USING (msisdn)
output:
  columns:
    msisdn: "User identifier"
    activity_score: "Weighted activity score"
```

### Feature Group

```yaml
kind: feature_group
name: user_behavior
description: "User behavioral features"
owner: ml-team@company.com
tags: [user, behavior]
entity:
  name: user
  join_keys: [msisdn]
materialization:
  event_time_col: event_timestamp
  offline:
    enabled: true
    format: parquet
  online:
    enabled: true
    ttl: 7d
inputs:
  - ref: cleaned_events
transform: |
  SELECT
    msisdn,
    COUNT(*) as event_count,
    AVG(value) as avg_value
  FROM {{ ref('cleaned_events') }}
  GROUP BY msisdn
features:
  event_count:
    description: "Total events"
    dtype: int
  avg_value:
    description: "Average value"
    dtype: float
tests:
  - not_null: [msisdn]
  - unique: [msisdn]
```

### Model

```yaml
kind: model
name: churn_predictor
description: "Predicts customer churn"
owner: ml-team@company.com
tags: [ml, churn]
output_columns:
  - churn_probability
  - churn_risk_tier
inputs:
  - ref: user_call_features
aggregation:
  id_col: msisdn
  feature_date_col: event_date
  application_date_col: prediction_date
  features:
    - name: call_count
      basic: [sum, mean, max]
      rolling:
        - window: [1, 7]
          aggs: [sum, count]
        - window: [8, 30]
          aggs: [sum, count]
training:
  label_source: churn_labels
  label_column: churned
  algorithm: xgboost
  params:
    n_estimators: 100
    max_depth: 6
tests:
  - min_accuracy: 0.8
  - min_auc: 0.85
  - no_train_serve_skew: true
```

### Aggregation

```yaml
kind: aggregation
name: user_behavioral_features
description: "Standard user behavioral aggregations"
owner: ml-team@company.com
id_col: msisdn
feature_date_col: event_date
application_date_col: prediction_date
features:
  - name: amount
    basic: [sum, mean, max, std]
    rolling:
      - window: [1, 7]
        aggs: [sum, mean]
      - window: [8, 30]
        aggs: [sum, mean]
    ratio:
      - numerator: [1, 30]
        denominator: [31, 90]
        aggs: [sum]
  - name: is_fraud
    since:
      - condition: "is_fraud == 1"
        aggs: [count, sum]
```

### Rule

```yaml
kind: rule
name: high_value_customer
description: "Identifies high value customers"
owner: business-team@company.com
params:
  revenue_threshold: 1000
  tenure_threshold: 12
rule:
  value: "total_revenue > {{ revenue_threshold }} AND tenure_months > {{ tenure_threshold }}"
```

---

## Appendix B: Comparison with dbt

| Aspect | dbt | Seeknal 2.0 |
|--------|-----|-------------|
| Primary language | SQL + Jinja2 | Python + SQL + YAML |
| Target audience | Analytics engineers | Data + ML engineers |
| Core abstraction | Models (tables/views) | Nodes (sources, features, models) |
| Dependency declaration | `ref()`, `source()` | `ref()`, `source()`, `use_*()` |
| Template system | Jinja2 macros | Parameterized YAML |
| Testing | Generic tests | Data quality + ML tests |
| Documentation | dbt docs | seeknal docs |
| Feature store | Not built-in | Core feature |
| ML models | Not built-in | First-class nodes |
| Online serving | Not built-in | Built-in |
| Train-serve skew | N/A | Prevented by design |

---

*This design document was created through collaborative brainstorming on 2026-01-08.*
